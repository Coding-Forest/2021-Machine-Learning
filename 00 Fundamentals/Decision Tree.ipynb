{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGrQ6zyMNqtR"
      },
      "source": [
        "# Decision Tree\n",
        "\n",
        "It is a binary decision making process to filter the best decision. At each step of the tree, the nodes (number of possible decisions) are divided in two smaller groups according to a condition (e.g. is the image grayscale or colour?) until the decision options in terminal nodes are indivisible.\n",
        "\n",
        "<br> \n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "[Decision Tree, Wikipedia](https://en.wikipedia.org/wiki/Decision_tree)\n",
        "\n",
        "A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It is one way to display an algorithm that only contains conditional control statements.\n",
        "\n",
        "Decision trees are commonly used in operations research, specifically in decision analysis, to help identify a strategy most likely to reach a goal, but are also a popular tool in machine learning.\n",
        "\n",
        "----\n",
        "\n",
        "A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute (e.g. whether a coin flip comes up heads or tails), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JdbK2M9O1Ln"
      },
      "source": [
        "## Entropy & Information Gain\n",
        "\n",
        "$Entropy = -p(+) \\cdot log(p(+)) - p(-) \\cdot log(p(-))$\n",
        "\n",
        "Example:\n",
        "\n",
        "In the total of 8 pictures, we want to search the family photo from winter vacation.\n",
        "\n",
        "**References**\n",
        "Minsuk Heo (2016) Machine Learning Decision Tree - Mathematical approach to ID3 Algorithm https://www.youtube.com/watch?v=UPKugq0fK04&ab_channel=MinsukHeo허민석"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgq-NOouMVgc",
        "outputId": "54b7f9ae-ae74-4c94-87f0-dc905e577237"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Entropy([1+, 7-]) - log base 2 was used here.\n",
        "entropy = -(1/8)*np.log2(1/8)-(7/8)*np.log2(7/8)\n",
        "np.round(entropy, 3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.544"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBuG7g2DRgnc"
      },
      "source": [
        "Information Gain (family photo from winter, cartoon)\n",
        "\n",
        "$E(\\text{winter family photo}) - E(\\text{winter family photo, cartoon})$\n",
        "\n",
        "entropy - (4/8 * E([0+, 4-]) + (4/8 * E([1+, 3-]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUfHKldAQR42",
        "outputId": "624aa12c-c817-4379-a130-9a389102d8fd"
      },
      "source": [
        "# IG(winter family photo, cartoon)\n",
        "cartoon_entropy = entropy - (4/8 * (- 1/4 * np.log2(1/4) - 3/4 * np.log2(3/4)))\n",
        "np.round(cartoon_entropy, 3)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.138"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXMe7FU4S_y8",
        "outputId": "ff4cd963-3203-46fe-b7a4-e3d1e633df4c"
      },
      "source": [
        "# IG(winter family photo, winter)\n",
        "winter_entropy = entropy - (5/8 * (np.log2(1/5)) + 3/8 * (np.log2(0/3)))\n",
        "np.round(winter_entropy, 4)     # correct answer = 0.093 ?"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log2\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0NiH-izUpwP"
      },
      "source": [
        "# IG(winter family photo, n_person > 1)\n",
        "person_entropy = entropy - (5/8 * (-5/8 * np.log2(5/8)) + 3/8 * (-3/8 * np.log2(3/8)))\n",
        "np.round(winter_entropy, 4)     # correct answer = 0.093 ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRl5F9XXS_t8"
      },
      "source": [
        "### Entropy Formula\n",
        "\n",
        "High entropy means high uncertainly.\n",
        "Low entropy means low uncertainty.\n",
        "$H(X)= -\\sum_{i=1}^{n}p_{i} \\cdot log_{2} \\cdot p_{i}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwA7ZkWmWIQA",
        "outputId": "6444536a-0655-4f2e-f18a-d2ae24d65337"
      },
      "source": [
        "# Coin toss \n",
        "# 50% 50% chance of head and tail\n",
        "-(0.5 * np.log2(0.5) + 0.5 * np.log2(0.5))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPReBG1OWddP",
        "outputId": "a96b4469-d905-46b8-d82c-9f126b0da689"
      },
      "source": [
        "# 100% head 0% tail\n",
        "-(np.log2(1) + 0 * np.log2(0.5))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW2rSaQtWmX7",
        "outputId": "1dc02dd4-f61d-44a1-da3a-7031d7019b24"
      },
      "source": [
        "# 90% head 10% tail\n",
        "entropy = -(0.9*np.log2(0.9) + 0.1 * np.log2(0.1))\n",
        "np.round(entropy, 2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}
